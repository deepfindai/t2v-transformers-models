services:
  deepfind-weaviate-t2v-transformers:
    build:
      context: .
      dockerfile: deepfind.Dockerfile
      args:
        # Se si usa MODEL_PATH, il modello viene preso dal folder
        #        - MODEL_PATH=./models/dpr/huggingface/dbmdz/bert-base-italian-uncased
        # Se si usa MODEL_NAME, il modello viene scaricato da HuggingFace
        - MODEL_NAME=efederici/mmarco-sentence-BERTino
    image: deepfindai/t2v-transformers:efederici.mmarco-sentence-BERTino
    container_name: deepfind-weaviate-t2v-transformers
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 0
              capabilities: [gpu]
    networks:
      - deepfind

networks:
  deepfind:
    name: 'deepfind'
    driver: bridge
